from functools import partial
import os
import argparse
import yaml
import sys

# # Add parent directory to Python path to import diss_modules
# sys.path.append('../../')

from diss_modules.reward import get_reward_method
from diss_modules.search import get_search_method
from diss_modules.eval import get_evaluation_table_string

import torch
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

from guided_diffusion.condition_methods import get_conditioning_method
from guided_diffusion.measurements import get_noise, get_operator
from guided_diffusion.unet import create_model

from guided_diffusion.diss_guided_diffusion import create_sampler  # changed to search guided gaussian diffusion


from dataloader import get_dataset, get_dataloader
from util.img_utils import clear_color, mask_generator
from util.logger import get_logger
import torchvision

import numpy as np
import random
from PIL import Image
import glob
from pathlib import Path

def seed_everything(seed: int):
    """Seed all random number generators for reproducibility."""
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    random.seed(seed)
    np.random.seed(seed)


def load_yaml(file_path: str) -> dict:
    with open(file_path) as f:
        config = yaml.load(f, Loader=yaml.FullLoader)
    return config


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--model_config', type=str)
    parser.add_argument('--diffusion_config', type=str)
    parser.add_argument('--task_config', type=str, default='./diss_configs/diss_super_resolution_config.yaml')
    parser.add_argument('--gpu', type=int, default=0)
    parser.add_argument('--timestep', type=int, default=100)
    parser.add_argument('--eta', type=float, default=0.5)
    parser.add_argument('--scale', type=float, default=10)
    parser.add_argument('--method', type=str, default='mpgd_wo_proj')
    parser.add_argument('--save_dir', type=str, default='./outputs/ffhq/')
    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--n_images', type=int, default=1)
    parser.add_argument('--metrics', type=str, nargs='+', default=['psnr', 'ssim', 'lpips', 'adaface', 'clip'])

    args = parser.parse_args()
   
    # logger
    logger = get_logger()

    # Set random seed
    seed_everything(args.seed)
    
    # Device setting
    device_str = f"cuda:{args.gpu}" if torch.cuda.is_available() else 'cpu'
    logger.info(f"Device set to {device_str}.")
    device = torch.device(device_str)  
    
    # Load configurations
    model_config = load_yaml(args.model_config)
    diffusion_config = load_yaml(args.diffusion_config)
    task_config = load_yaml(args.task_config)   
    
    if args.timestep < 1000:
        diffusion_config["timestep_respacing"] = f"ddim{args.timestep}"
        diffusion_config["rescale_timesteps"] = True
    else:
        diffusion_config["timestep_respacing"] = f"1000"
        diffusion_config["rescale_timesteps"] = False
    
    diffusion_config["eta"] = args.eta
    task_config["conditioning"]["method"] = args.method
    task_config["conditioning"]["params"]["scale"] = args.scale
    
    # Load model
    model = create_model(**model_config)
    model = model.to(device)
    model.eval()

    # Prepare Operator and noise
    measure_config = task_config['measurement']
    operator = get_operator(device=device, **measure_config['operator'])
    noiser = get_noise(**measure_config['noise'])
    logger.info(f"Operation: {measure_config['operator']['name']} / Noise: {measure_config['noise']['name']}")

    # Prepare conditioning method
    cond_config = task_config['conditioning']
    # cond_method = get_conditioning_method(cond_config['method'], operator, noiser, resume = "../nonlinear/SD_style/models/ldm/celeba256/model.ckpt", **cond_config['params']) # in the paper we used this checkpoint
    cond_method = get_conditioning_method(cond_config['method'], operator, noiser, resume = "../nonlinear/SD_style/models/ldm/ffhq256/model.ckpt", **cond_config['params']) # you can probably also use this checkpoint, but you probably want to tune the hyper-parameter a bit
    measurement_cond_fn = cond_method.conditioning
    logger.info(f"Conditioning method : {task_config['conditioning']['method']}")
   
    # Load diffusion sampler
    sampler = create_sampler(**diffusion_config) 
    sample_fn = partial(sampler.p_sample_loop, model=model, measurement_cond_fn=measurement_cond_fn)


    # get rewards:
    rewards_cfg = task_config['rewards']
    gradient_rewards = [
        get_reward_method(cfg['name'], **{k: v for k, v in cfg.items() if k not in ['name', 'steering']})
        for cfg in rewards_cfg if 'gradient' in cfg.get('steering', [])
    ]

    search_rewards = [
        get_reward_method(cfg['name'], **{k: v for k, v in cfg.items() if k not in ['name', 'steering']})
        for cfg in rewards_cfg if 'search' in cfg.get('steering', [])
    ]

    # get search algorithm:
    num_particles = task_config['num_particles']
    MAX_BATCH_SIZE = 8
    batch_size = num_particles if num_particles <= MAX_BATCH_SIZE else MAX_BATCH_SIZE
    search = get_search_method(num_particles=batch_size, **task_config['search_algorithm']) if search_rewards else None

    print(f'batch size: {batch_size}')

   
    # Working directory
    import datetime
    timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    dir_path = f"{timestamp}_{diffusion_config['timestep_respacing']}_eta{args.eta}_scale{args.scale}"


    task_name = measure_config['operator']['name']

    if task_name == 'super_resolution':
        task_name = f"{task_name}_x{measure_config['operator']['scale_factor']}"
    out_path = os.path.join(args.save_dir, task_name, task_config['conditioning']['method'], dir_path)
    
    os.makedirs(out_path, exist_ok=True)
    for img_dir in ['input', 'recon', 'progress', 'label', 'metrics']:
        os.makedirs(os.path.join(out_path, img_dir), exist_ok=True)

    # Prepare dataloader
    data_config = task_config['data']
    transform = transforms.Compose([transforms.ToTensor(),
                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
    dataset = get_dataset(**data_config, transforms=transform)
    loader = get_dataloader(dataset, batch_size=1, num_workers=0, train=False)

    img_size = 256


    print(f'num particles: {num_particles}')
    print(f'n_images: {args.n_images}')


    # add all the configs to the markdown table
    markdown_table = f'arguments: \n \n'
    for arg, value in vars(args).items():
        markdown_table += f'- **{arg}**: {value} \n '

    all_tables = []
    num_runs = 1
        
    # Do Inference
    for i, ref_img in enumerate(loader):

        # set the side info for the rewards
        for reward in search_rewards + gradient_rewards:
            reward.set_side_info(i)

        
        if i >= args.n_images:
            break

        fname = f'{i:03}'

        ref_img = ref_img.to(device)

        print(f'ref_img shape: {ref_img.shape}')
        # print(f'ref_face_img shape: {ref_face_img.shape}')

        # Forward measurement model (Ax + n)
        y = operator.forward(ref_img)
        y_n = noiser(y)

        # Sampling
        x_start = torch.randn((batch_size, 3, img_size, img_size), device=device).requires_grad_()
        print(f"x_start shape: {x_start.shape}")

        plt.imsave(os.path.join(out_path, 'input', f'{i:03}_input.png'), clear_color(y_n))
        plt.imsave(os.path.join(out_path, 'label', f'{i:03}_label.png'), clear_color(ref_img))
        # plt.imsave(os.path.join(out_path, 'guid', f'{i:03}_guid.png'), clear_color(ref_face_img))


        sample = sample_fn(x_start=x_start,
                           measurement=y_n, 
                           record=False, 
                           save_root=out_path, 
                           cond_scale=args.scale,
                           gradient_rewards=gradient_rewards,
                           search_rewards=search_rewards,
                           search=search
                        )

        for particle in range(batch_size):
            plt.imsave(
                os.path.join(out_path, 'recon', 'img_' + fname + '_' + str(particle + batch_size) + '.png'),
                clear_color(sample[particle].unsqueeze(0))
            )
            print(f'saved {particle}th particle')


        logger.info('')
        table = get_evaluation_table_string(sample, ref_img.repeat(batch_size, 1, 1, 1), args.metrics)
        all_tables.append(table)
        print(table)
    

if __name__ == '__main__':
    main()
